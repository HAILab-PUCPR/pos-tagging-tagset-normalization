{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@author: Lucas Ferro Antunes de Oliveira\n",
    "\n",
    "This script transform the PUCPR corpus tagset to PennTreebank tagset (with no INFLECTION tags)\n",
    "The original tagset: https://visl.sdu.dk/visl/pt/info/portsymbol.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import collections\n",
    "import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH_CORPORA = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to count words and tags in the corpus\n",
    "\n",
    "dictTags = {}\n",
    "dictTagsPostNormalization = {}\n",
    "dictTagsPostNormalization2 = {}\n",
    "\n",
    "dictPRN = {}\n",
    "dictART= {}\n",
    "dictN = {}\n",
    "dictPREP = {}\n",
    "dictADV = {}\n",
    "dictNUM = {}\n",
    "dictADJ = {}\n",
    "dictIN = {}\n",
    "dictNPROP = {}\n",
    "dictPCP = {}\n",
    "dictV = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More dictionaries\n",
    "\n",
    "dictPRN2 = {}\n",
    "dictART2= {}\n",
    "dictN2 = {}\n",
    "dictPREP2 = {}\n",
    "dictADV2 = {}\n",
    "dictNUM2 = {}\n",
    "dictADJ2 = {}\n",
    "dictIN2 = {}\n",
    "dictNPROP2 = {}\n",
    "dictPCP2 = {}\n",
    "dictV2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a new corpus file with the adapted tagset\n",
    "\n",
    "fw = io.open(_PATH_CORPORA + \"PUCPR-tagset-adapted-penntreebank-update.txt\",'w',encoding='utf8')\n",
    "fw.write(\"-DOCSTART- -X- -X- O\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new corpus file with the adapted normalized tagset\n",
    "\n",
    "fw2 = io.open(_PATH_CORPORA + \"PUCPR-tagset-adapted-penntrebank-no-accents.txt\",'w',encoding='utf8')\n",
    "fw2.write(\"-DOCSTART- -X- -X- O\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open corpus\n",
    "\n",
    "with io.open(_PATH_CORPORA + \"corpora\\PUCPR.txt\",'r',encoding='utf8') as f:\n",
    "    \n",
    "    # Get the text\n",
    "    text = f.read()\n",
    "    \n",
    "    # Define replace lists\n",
    "    # More on https://www.infoescola.com/portugues/pronomes/ and https://www.infoescola.com/portugues/adverbios/\n",
    "    PRNtoDT = [\"esta\", \"este\", \"estas\", \"estes\", \"isto\", \"isso\", \"aquilo\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"sua\", \"seu\", \"suas\", \"seus\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"demais\", \"os demais\", \"as demais\", \"todo\", \"todos\", \"qual\",\"alguma\",\"algum\",\"algumas\",\"alguns\",\"outro\",\"outra\",\"outros\",\"outras\",\"mesmo\",\"mesma\",\"mesmos\",\"mesmas\",\"neste\",\"nesta\",\"nestes\",\"nestas\",\"tanto\",\"cada\", \"quanto\", \"quantos\", \"quanta\", \"quantas\"]\n",
    "    PRNtoPRP = [\"eu\", \"tu\", \"ele\", \"ela\", \"nós\", \"vós\", \"eles\", \"elas\", \"me\", \"mim\", \"comigo\", \"te\", \"ti\", \"contigo\", \"se\", \"si\", \"consigo\", \"o\", \"a\", \"lhe\", \"nos\", \"conosco\", \"vos\", \"convosco\", \"os\", \"as\", \"lhes\", \"lo\", \"la\", \"los\", \"las\", \"mim\"]\n",
    "    PRNtoPRPS = [\"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\",\"teus\", \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"seu\", \"sua\", \"seus\", \"suas\"]\n",
    "        \n",
    "    #Iterate through sentences\n",
    "    for s in text.split(\"\\n\"):\n",
    "        \n",
    "        fw.write(\"\\n\")\n",
    "        \n",
    "        #Iterate through tokens\n",
    "        for t in s.split(\" \"):\n",
    "            \n",
    "            item = t.split(\"_\")\n",
    "             \n",
    "            word = item[0]\n",
    "                \n",
    "            tag = item[1]\n",
    "            \n",
    "            dictTags[tag] = dictTags.get(tag, 0) + 1\n",
    "            \n",
    "            \n",
    "            # REPLACE RULES\n",
    "            \n",
    "            # 1) ART -> DT (determiners)\n",
    "            if tag.upper() == \"ART\":\n",
    "                if word.lower() == \"uterina\" and tag.upper() == \"ART\":  #Specific rule for (uterina == art) / 1 error\n",
    "                    tag = tag.replace(\"ART\", \"ADJ\")\n",
    "                else:\n",
    "                    tag = tag.replace(\"ART\", \"DT\")\n",
    "                    dictART[word] = dictART.get(word, 0) + 1\n",
    "            \n",
    "            # 2) IN -> UH (interjections)\n",
    "            if tag.upper() == \"IN\":\n",
    "                dictIN[word] = dictIN.get(word, 0) + 1\n",
    "                tag = tag.replace(\"IN\", \"UH\")\n",
    "            \n",
    "            # 3) CJ -> CC or IN (Coordinating and subordinating conjunctions)\n",
    "            if tag.upper() == \"CJ\":\n",
    "                if word.lower() == \"e\" or word.lower() == \"ou\":  \n",
    "                    tag = \"CC\" #e, ou (coordinating conjuctions)\n",
    "                else:\n",
    "                    tag = \"IN\" # \"que\", \"se\", \"porque\", etc (subordinating conjuctions)\n",
    "    \n",
    "            # 4) PCP -> VB (past participle -> verb base form)\n",
    "            if tag.upper() == \"PCP\":\n",
    "                tag = tag.replace(\"PCP\", \"VB\")\n",
    "                dictPCP[word] = dictPCP.get(word, 0) + 1\n",
    "            \n",
    "            # 5) PRN -> (SPEC / PRP / DT / ADJ)\n",
    "            if tag.upper() == \"PRN\":\n",
    "                \n",
    "                dictPRN[word] = dictPRN.get(word, 0) + 1\n",
    "                \n",
    "                if word.lower() in PRNtoDT:  #determiners\n",
    "                    tag = \"DT\"\n",
    "                else:\n",
    "                    if word.lower() == \"próprio\":  #specific rule\n",
    "                        tag = \"ADJ\"\n",
    "                    else:\n",
    "                        if word.lower() in PRNtoPRP:  #personal pronouns \n",
    "                            tag = \"PRP\"\n",
    "                        else:\n",
    "                            ###if word.lower() in PRNtoSPEC:  #No matching tag in Penn Treebank Tagset\n",
    "                                ###tag = \"SPEC\"\n",
    "                            ###else:\n",
    "                            if word.lower() in PRNtoPRPS: #pocessive pronouns\n",
    "                                tag = \"PRP$\"\n",
    "                            else:\n",
    "                                tag = \"DT\" #determiners\n",
    "                                \n",
    "            # 6) NPROP -> NNP (Proper Nouns Singular)\n",
    "            if tag.upper() == \"NPROP\":\n",
    "                dictNPROP[word] = dictNPROP.get(word, 0) + 1\n",
    "                tag = tag.replace(\"NPROP\", \"NNP\") #(Proper Nouns Singular)\n",
    "                     \n",
    "            # 7) Rule for \"x\" when it's tagged as preposition - manually check if it's plural or singular\n",
    "            if tag.upper() == \"PREP\" and word.lower() == \"x\":\n",
    "                word = word.replace(\"x\", \"vezes\")\n",
    "            \n",
    "            # 8) PREP -> IN (Preposition)\n",
    "            if tag.upper() == \"PREP\":\n",
    "                dictPREP[word] = dictPREP.get(word, 0) + 1\n",
    "                tag = tag.replace(\"PREP\", \"IN\")\n",
    "            \n",
    "            # 9) N -> NN (noun, singular)\n",
    "            if len(tag) == 1 and tag == \"N\":\n",
    "                if tag.upper() == \"N\":\n",
    "                    dictN[word] = dictN.get(word, 0) + 1    \n",
    "                    tag = tag.replace(\"N\", \"NN\")\n",
    "               \n",
    "            # 10) ADV -> RB (adverb)\n",
    "            if tag.upper() == \"ADV\":\n",
    "                dictADV[word] = dictADV.get(word, 0) + 1\n",
    "                tag = tag.replace(\"ADV\", \"RB\")\n",
    "            \n",
    "            # 11) NUM -> CD (cardinal numbers)\n",
    "            if tag.upper() == \"NUM\":\n",
    "                dictNUM[word] = dictNUM.get(word, 0) + 1\n",
    "                tag = tag.replace(\"NUM\", \"CD\")\n",
    "            \n",
    "            # 12) ADJ -> JJ (adjectives)\n",
    "            if tag.upper() == \"ADJ\":\n",
    "                dictADJ[word] = dictADJ.get(word, 0) + 1\n",
    "                tag = tag.replace(\"ADJ\", \"JJ\")\n",
    "            \n",
    "            # 13) V -> VB (verbs)\n",
    "            if len(tag) == 1 and tag == \"V\":\n",
    "                if tag.upper() == \"V\":\n",
    "                    dictV[word] = dictV.get(word, 0) + 1\n",
    "                    tag = tag.replace(\"V\", \"VB\") #Verbs on base form\n",
    "            \n",
    "            dictTagsPostNormalization[tag] = dictTagsPostNormalization.get(tag, 0) + 1\n",
    "            \n",
    "            # Write \n",
    "            fw.write(word + \" \" + tag + \" \" + \"O - O\" + \"\\n\")\n",
    "            \n",
    "        # Close sentence\n",
    "        fw.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open corpus\n",
    "with io.open(_PATH_CORPORA + \"corpora\\PUCPR.txt\",'r',encoding='utf8') as f:\n",
    "    \n",
    "    # Get the text\n",
    "    text = f.read()\n",
    "    \n",
    "    # Define replace lists\n",
    "    # More on https://www.infoescola.com/portugues/pronomes/ and https://www.infoescola.com/portugues/adverbios/\n",
    "    PRNtoDT = [\"esta\", \"este\", \"estas\", \"estes\", \"isto\", \"isso\", \"aquilo\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"sua\", \"seu\", \"suas\", \"seus\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"demais\", \"os demais\", \"as demais\", \"todo\", \"todos\", \"qual\",\"alguma\",\"algum\",\"algumas\",\"alguns\",\"outro\",\"outra\",\"outros\",\"outras\",\"mesmo\",\"mesma\",\"mesmos\",\"mesmas\",\"neste\",\"nesta\",\"nestes\",\"nestas\",\"tanto\",\"cada\", \"quanto\", \"quantos\", \"quanta\", \"quantas\"]\n",
    "    PRNtoPRP = [\"eu\", \"tu\", \"ele\", \"ela\", \"nós\", \"vós\", \"eles\", \"elas\", \"me\", \"mim\", \"comigo\", \"te\", \"ti\", \"contigo\", \"se\", \"si\", \"consigo\", \"o\", \"a\", \"lhe\", \"nos\", \"conosco\", \"vos\", \"convosco\", \"os\", \"as\", \"lhes\", \"lo\", \"la\", \"los\", \"las\", \"mim\"]\n",
    "    PRNtoPRPS = [\"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\",\"teus\", \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"seu\", \"sua\", \"seus\", \"suas\"]\n",
    "    ###PRNtoSPEC = [\"que\", \"quem\", \"nada\", \"cada um\", \"as quais\", \"os quais\", \"a qual\", \"o qual\", \"onde\", \"todo o mundo\"]\n",
    "    \n",
    "    #Iterate through sentences\n",
    "    for s in text.split(\"\\n\"):\n",
    "        \n",
    "        fw2.write(\"\\n\")\n",
    "        #Iterate through tokens\n",
    "        for t in s.split(\" \"):\n",
    "            \n",
    "            item = t.split(\"_\")\n",
    "            \n",
    "            #normalize accents and cases\n",
    "            wordNorm = item[0]\n",
    "            \n",
    "            for i in wordNorm:\n",
    "                accented_word = wordNorm\n",
    "                # accented_word is of type 'unicode'\n",
    "            \n",
    "                unaccented_word = unidecode.unidecode(accented_word)\n",
    "                # unaccented_word contains 'Malaga'and is of type 'str'\n",
    "                \n",
    "            for i in unaccented_word:\n",
    "                lowerword = unaccented_word.lower()\n",
    "            \n",
    "            tag2 = item[1]\n",
    "            \n",
    "            \n",
    "            # REPLACE RULES\n",
    "            \n",
    "            # 1) ART -> DT (determiners)\n",
    "            if tag2.upper() == \"ART\":\n",
    "                if lowerword.lower() == \"uterina\" and tag2.upper() == \"ART\":  #Specific rule for (uterina == art) / 1 error\n",
    "                    tag2 = tag2.replace(\"ART\", \"ADJ\")\n",
    "                else:\n",
    "                    tag2 = tag2.replace(\"ART\", \"DT\")\n",
    "                    dictART2[lowerword] = dictART2.get(lowerword, 0) + 1\n",
    "                    \n",
    "            # 2) IN -> UH (interjections)\n",
    "            if tag2.upper() == \"IN\":\n",
    "                dictIN2[lowerword] = dictIN2.get(lowerword, 0) + 1\n",
    "                tag2 = tag2.replace(\"IN\", \"UH\")\n",
    "            \n",
    "            # 3) CJ -> CC or IN (Coordinating and subordinating conjunctions)\n",
    "            if tag2.upper() == \"CJ\":\n",
    "                if lowerword.lower() == \"e\" or lowerword.lower() == \"ou\":  \n",
    "                    tag2 = \"CC\" #e, ou (coordinating conjuctions)\n",
    "                else:\n",
    "                    tag2 = \"IN\" # \"que\", \"se\", \"porque\", etc (subordinating conjuctions)\n",
    "    \n",
    "            # 4) PCP -> VBN (past participle -> verb base form)\n",
    "            if tag2.upper() == \"PCP\":\n",
    "                tag2 = tag2.replace(\"PCP\", \"VB\")\n",
    "                dictPCP2[lowerword] = dictPCP2.get(lowerword, 0) + 1\n",
    "            \n",
    "            # 5) PRN -> (SPEC / PRP / DT / ADJ)\n",
    "            if tag2.upper() == \"PRN\":\n",
    "                \n",
    "                dictPRN2[lowerword] = dictPRN2.get(lowerword, 0) + 1\n",
    "                \n",
    "                if lowerword.lower() in PRNtoDT:  #determiners\n",
    "                    tag2 = \"DT\"\n",
    "                else:\n",
    "                    if lowerword.lower() == \"próprio\":  #specific rule\n",
    "                        tag2 = \"ADJ\"\n",
    "                    else:\n",
    "                        if lowerword.lower() in PRNtoPRP:  #personal pronouns \n",
    "                            tag2 = \"PRP\"\n",
    "                        else:\n",
    "                            ###if word.lower() in PRNtoSPEC:  #No matching in Penn Treebank\n",
    "                                ###tag = \"SPEC\"\n",
    "                            ###else:\n",
    "                            if lowerword.lower() in PRNtoPRPS: #pocessive pronouns\n",
    "                                tag2 = \"PRP$\"\n",
    "                            else:\n",
    "                                tag2 = \"DT\" #determiners\n",
    "                            \n",
    "            # 6) NPROP -> NNP (Proper Nouns Singular)\n",
    "            if tag2.upper() == \"NPROP\":\n",
    "                dictNPROP2[lowerword] = dictNPROP2.get(lowerword, 0) + 1\n",
    "                tag2 = tag2.replace(\"NPROP\", \"NNP\") #(Proper Nouns Singular)\n",
    "            \n",
    "           \n",
    "            # 7) Rule for \"x\" when it's tagged as preposition - manually check if it's plural or singular\n",
    "            if tag2.upper() == \"PREP\" and lowerword.lower() == \"x\":\n",
    "                lowerword = lowerword.replace(\"x\", \"vezes\")\n",
    "            \n",
    "            # 8) PREP -> IN (Preposition)\n",
    "            if tag2.upper() == \"PREP\":\n",
    "                dictPREP2[lowerword] = dictPREP2.get(lowerword, 0) + 1\n",
    "                tag2 = tag2.replace(\"PREP\", \"IN\")\n",
    "            \n",
    "            # 9) N -> NN (noun, singular)\n",
    "            if len(tag2) == 1 and tag2 == \"N\":\n",
    "                if tag2.upper() == \"N\":\n",
    "                    dictN2[lowerword] = dictN2.get(lowerword, 0) + 1    \n",
    "                    tag2 = tag2.replace(\"N\", \"NN\")  #(Noun, Singular)\n",
    "               \n",
    "            # 10) ADV -> RB (adverb)\n",
    "            if tag2.upper() == \"ADV\":\n",
    "                dictADV2[lowerword] = dictADV2.get(lowerword, 0) + 1\n",
    "                tag2 = tag2.replace(\"ADV\", \"RB\")\n",
    "            \n",
    "            # 11) NUM -> CD (cardinal numbers)\n",
    "            if tag2.upper() == \"NUM\":\n",
    "                dictNUM2[lowerword] = dictNUM2.get(lowerword, 0) + 1\n",
    "                tag2 = tag2.replace(\"NUM\", \"CD\")\n",
    "            \n",
    "            # 12) ADJ -> JJ (adjectives)\n",
    "            if tag2.upper() == \"ADJ\":\n",
    "                dictADJ2[lowerword] = dictADJ2.get(lowerword, 0) + 1\n",
    "                tag2 = tag2.replace(\"ADJ\", \"JJ\")\n",
    "            \n",
    "            # 13) V -> VB (verbs)\n",
    "            if len(tag2) == 1 and tag2 == \"V\":\n",
    "                if tag2.upper() == \"V\":\n",
    "                    dictV2[lowerword] = dictV2.get(lowerword, 0) + 1\n",
    "                    tag2 = tag2.replace(\"V\", \"VB\") #Verbs on base form\n",
    "            \n",
    "            # Other corrections - Common errors\n",
    "            \n",
    "            # If the word isso is labelled as DET (UNIFESP corpus está como SPEC)\n",
    "                \n",
    "            #TODO: If you find any other common error - put the correction here\n",
    "            \n",
    "            #TODO: normalize multiword expressions like UNIFESP corpus\n",
    "            \n",
    "            # Normalization survey\n",
    "            dictTagsPostNormalization2[tag2] = dictTagsPostNormalization2.get(tag2, 0) + 1\n",
    "            \n",
    "            # Write\n",
    "            fw2.write(lowerword + \" \" + tag2 + \" \" + \"O - O\" + \"\\n\")\n",
    "            \n",
    "        fw2.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of tags inside the corpus\n",
    "numberoftags = []\n",
    "for key, value in sorted(dictTagsPostNormalization.items(), key=lambda x:-x[1]):\n",
    "    numberoftags.append(value)\n",
    "    \n",
    "totalnumber = sum(numberoftags)\n",
    "print(totalnumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cells show every word and its count in the corpus for each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictTagsPostNormalization.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictTagsPostNormalization2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictTags.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, value in sorted(dictART.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictART2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPCP.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPCP2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPRN.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPRN2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNPROP.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNPROP2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPREP.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPREP2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictN.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictN2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictADV.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictADV2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNUM.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNUM2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictADJ.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictADJ2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictIN.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictIN2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictV.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictV2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
