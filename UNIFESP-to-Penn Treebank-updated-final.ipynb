{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "@author: Lucas Ferro Antunes de Oliveira\n",
    "\n",
    "This script transform the UNIFESP corpus tagset to Penn Treebank tagset (with some inflection tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import collections\n",
    "import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH_CORPORA = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to count words and tags in the corpus\n",
    "\n",
    "dictTags = {}\n",
    "dictTagsPostNormalization = {}\n",
    "\n",
    "dictIN = {}\n",
    "dictDT= {}\n",
    "dictNN = {}\n",
    "dictNNS = {}\n",
    "dictCD = {}\n",
    "dictJJ = {}\n",
    "dictPRP = {}\n",
    "dictNNP = {}\n",
    "dictVB = {}\n",
    "dictVBP = {}\n",
    "dictVBG = {}\n",
    "dictVBN = {}\n",
    "dictRB = {}\n",
    "dictCC = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictTags2 = {}\n",
    "dictTagsPostNormalization2 = {}\n",
    "\n",
    "dictIN2 = {}\n",
    "dictDT2= {}\n",
    "dictNN2 = {}\n",
    "dictNNS2 = {}\n",
    "dictCD2 = {}\n",
    "dictJJ2 = {}\n",
    "dictPRP2 = {}\n",
    "dictNNP2 = {}\n",
    "dictVB2 = {}\n",
    "dictVBP2 = {}\n",
    "dictVBG2 = {}\n",
    "dictVBN2 = {}\n",
    "dictRB2 = {}\n",
    "dictCC2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new corpus file with the adapted tagset\n",
    "fw = io.open(_PATH_CORPORA + \"UNIFESP-tagset-adapted-penntreebank-update.txt\",'w',encoding='utf8')\n",
    "fw.write(\"-DOCSTART- -X- -X- O\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new corpus file with the adapted tagset with no accents\n",
    "fw2 = io.open(_PATH_CORPORA + \"UNIFESP-tagset-adapted-penntreebank-no-accents.txt\",'w',encoding='utf8')\n",
    "fw2.write(\"-DOCSTART- -X- -X- O\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open corpus\n",
    "with io.open(_PATH_CORPORA + \"corpora/UNIFESP.txt\", 'r', encoding='utf8') as f:\n",
    "    \n",
    "    # Get the text\n",
    "    text = f.read()\n",
    "    \n",
    "    # Define replace lists\n",
    "    # More on https://www.infoescola.com/portugues/pronomes/ and https://www.infoescola.com/portugues/adverbios/\n",
    "    PRNtoDT = [\"esta\", \"este\", \"estas\", \"estes\", \"isto\", \"isso\", \"aquilo\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"sua\", \"seu\", \"suas\", \"seus\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"demais\", \"os demais\", \"as demais\", \"todo\", \"todos\", \"qual\",\"alguma\",\"algum\",\"algumas\",\"alguns\",\"outro\",\"outra\",\"outros\",\"outras\",\"mesmo\",\"mesma\",\"mesmos\",\"mesmas\",\"neste\",\"nesta\",\"nestes\",\"nestas\",\"tanto\",\"cada\", \"quanto\", \"quantos\", \"quanta\", \"quantas\"]\n",
    "    PRNtoPRP = [\"eu\", \"tu\", \"ele\", \"ela\", \"nós\", \"vós\", \"eles\", \"elas\", \"me\", \"mim\", \"comigo\", \"te\", \"ti\", \"contigo\", \"se\", \"si\", \"consigo\", \"o\", \"a\", \"lhe\", \"nos\", \"conosco\", \"vos\", \"convosco\", \"os\", \"as\", \"lhes\", \"lo\", \"la\", \"los\", \"las\", \"mim\"]\n",
    "    PRNtoPRPS = [\"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\",\"teus\", \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"seu\", \"sua\", \"seus\", \"suas\"]\n",
    "    \n",
    "    #Iterate through sentences\n",
    "    for s in text.split(\"\\n\"):\n",
    "        \n",
    "        fw.write(\"\\n\")\n",
    "        \n",
    "        #Iterate through tokens\n",
    "        for t in s.split(\" \"):\n",
    "            \n",
    "            item = t.split(\"_\")\n",
    "             \n",
    "            word = item[0]\n",
    "            \n",
    "            tag = item[1]\n",
    "               \n",
    "            dictTags[tag] = dictTags.get(tag, 0) + 1\n",
    "            \n",
    "            # Replace Rules\n",
    "            \n",
    "            # 1) PRP to IN (prepositions)\n",
    "            if tag.upper() == \"PRP\":\n",
    "                tag = tag.replace(\"PRP\", \"IN\")\n",
    "                dictIN[word] = dictIN.get(word, 0) + 1\n",
    "            \n",
    "            # 2) N and its inflections to NN and NNS (singular nouns and plural nouns)\n",
    "            if tag.startswith(\"N\"):\n",
    "                \n",
    "                # 2.1) NFS and NMS to NN (singular nouns)\n",
    "                tag = tag.replace(\"NFS\", \"NN\")\n",
    "                tag = tag.replace(\"NMS\", \"NN\")\n",
    "                if tag.upper() == \"NN\":\n",
    "                    dictNN[word] = dictNN.get(word, 0) + 1\n",
    "                \n",
    "                # 2.2) NMP and NFP to NNS (plural nouns)\n",
    "                tag = tag.replace(\"NMP\", \"NN\")\n",
    "                tag = tag.replace(\"NFP\", \"NN\")\n",
    "                if tag.upper() == \"NNS\":\n",
    "                    dictNN[word] = dictNN.get(word, 0) + 1\n",
    "                \n",
    "                # 2.3) NM to NN (singular nouns)\n",
    "                tag = tag.replace(\"NM\", \"NN\")\n",
    "                dictNN[word] = dictNN.get(word, 0) + 1\n",
    "            \n",
    "            # 3) PROP to NNP (proper nouns)\n",
    "            if tag.startswith(\"PROP\"):\n",
    "                tag = \"NNP\"\n",
    "                dictNNP[word] = dictNNP.get(word, 0) + 1\n",
    "            \n",
    "            # 4) generic rule for verbs\n",
    "            if tag.startswith(\"V\"):\n",
    "            \n",
    "                # 4.1) VINF to VB (verbs in base form)\n",
    "                if tag.upper() == \"VINF\":\n",
    "                    tag = tag.replace(\"VINF\", \"VB\")\n",
    "                    dictVB[word] = dictVB.get(word, 0) + 1\n",
    "                \n",
    "                # 4.2) VFIN to VB (non-third person verbs, singular present)\n",
    "                elif tag.upper() == \"VFIN\":\n",
    "                    tag = tag.replace(\"VFIN\", \"VB\")\n",
    "                    dictVB[word] = dictVB.get(word, 0) + 1\n",
    "                \n",
    "                # 4.3) VGER to VB (gerund verbs)\n",
    "                elif tag.upper() == \"VGER\":\n",
    "                    tag = tag.replace(\"VGER\", \"VB\")\n",
    "                    dictVB[word] = dictVB.get(word, 0) + 1\n",
    "                \n",
    "                # 4.4) VPCP and its inflections to VB (past participle verb)  \n",
    "                elif tag.startswith(\"VPCP\"):\n",
    "                    tag = tag.replace(\"VPCPMS\", \"VB\")\n",
    "                    tag = tag.replace(\"VPCPFS\", \"VB\")\n",
    "                    tag = tag.replace(\"VPCPMP\", \"VB\")\n",
    "                    tag = tag.replace(\"VPCPFP\", \"VB\")\n",
    "                    dictVB[word] = dictVB.get(word, 0) + 1\n",
    "                    \n",
    "                else:\n",
    "                    tag = \"VB\"\n",
    "                    dictVB[word] = dictVB.get(word, 0) + 1\n",
    "            \n",
    "            # 5) SPEC to DT (determiners)\n",
    "            if tag.startswith(\"SPEC\"):\n",
    "                tag = \"DT\"\n",
    "                dictDT[word] = dictDT.get(word, 0) + 1\n",
    "            \n",
    "            # 6) DET and its inflections to DT (determiners)\n",
    "            if tag.startswith(\"DET\"):\n",
    "                tag = \"DT\"\n",
    "                dictDT[word] = dictDT.get(word, 0) + 1\n",
    "            \n",
    "            # 7) PERS to PRP (personal pronouns)\n",
    "            if tag.startswith(\"PERS\"):\n",
    "                tag = \"PRP\"\n",
    "                dictPRP[word] = dictPRP.get(word, 0) + 1\n",
    "            \n",
    "            # 8) ADJ to JJ (adjetives)\n",
    "            if tag.startswith(\"ADJ\"):\n",
    "                tag = \"JJ\"\n",
    "                dictJJ[word] = dictJJ.get(word, 0) + 1\n",
    "            \n",
    "            # 9) NUM and its inflections to CD (cardinal numbers)\n",
    "            if tag.startswith(\"NUM\"):\n",
    "                tag = \"CD\"\n",
    "                dictCD[word] = dictCD.get(word, 0) + 1\n",
    "            \n",
    "            # 10) ADV to RB (adverbs)\n",
    "            if tag.startswith(\"ADV\"):\n",
    "                tag = \"RB\"\n",
    "                dictRB[word] = dictRB.get(word, 0) + 1\n",
    "            \n",
    "            # 11) KC to CC or IN (coordinating or subordinating conjunctions)\n",
    "            if tag.upper() == \"KC\":\n",
    "                if word.lower() == \"e\" or word.lower() == \"ou\":  \n",
    "                    #e, ou (coordinating conjuctions)\n",
    "                    tag = \"CC\" \n",
    "                    dictCC[word] = dictCC.get(word, 0) + 1\n",
    "                else:\n",
    "                    # \"que\", \"se\", \"porque\", etc (subordinating conjuctions)\n",
    "                    tag = \"IN\"\n",
    "                    dictIN[word] = dictIN.get(word, 0) + 1\n",
    "            \n",
    "            # 12) KS to IN (subordinating conjunctions)\n",
    "            if tag.upper() == \"KS\":\n",
    "                tag = \"IN\"\n",
    "                dictIN[word] = dictIN.get(word, 0) + 1\n",
    "            \n",
    "            # Other corrections - Common errors\n",
    "            # 13) If the word SUS is labelled as an interjection\n",
    "            if word.lower() == \"sus\" and tag.upper() == \"IN\":\n",
    "                word = \"SUS\"\n",
    "                tag = \"NNP\"\n",
    "                dictNNP[word] = dictNNP.get(word, 0) + 1\n",
    "            \n",
    "            # 14) Rule for 'finanças', probably tagged wrong\n",
    "            if tag.upper() == \"<NFP\":\n",
    "                tag = tag.replace(\"<NFP\", \"NN\")\n",
    "                dictNN[word] = dictNN.get(word, 0) + 1\n",
    "            \n",
    "            # 15) \"SEM\" is tagged as hyphen-separated and it's not. Switch to preposition\n",
    "            if word.lower() == \"sem\" and tag.upper() == \"EC\":\n",
    "                tag = tag.replace(\"EC\", \"IN\")\n",
    "                dictIN[word] = dictIN.get(word, 0) + 1\n",
    "             \n",
    "            # 16) \"PRÉ\" is tagged as hyphen-separated and it's not in the text. Switch to noun\n",
    "            if word.lower() == \"pré\" and tag.upper() == \"EC\":\n",
    "                tag = tag.replace(\"EC\", \"NN\")\n",
    "                dictNN[word] = dictNN.get(word, 0) + 1\n",
    "            \n",
    "            # 17) \"MICRO\" is tagged as hyphen-separated and it's not. Switch to noun\n",
    "            if word.lower() == \"micro\" and tag.upper() == \"EC\":\n",
    "                tag = tag.replace(\"EC\", \"NN\")\n",
    "                dictNN[word] = dictNN.get(word, 0) + 1\n",
    "            \n",
    "            ### Review word \"Espontânea\" - line 2972 - UNIFESP, with two tags for being spread out ###\n",
    "            ### Review words of type \"de=acordo\" tagged with \"PP\" ###\n",
    "            \n",
    "            #TODO: If you find any other common error - put the correction here\n",
    "            \n",
    "            \n",
    "            #Dict for post normalization tags analysis\n",
    "            dictTagsPostNormalization[tag] = dictTagsPostNormalization.get(tag, 0) + 1\n",
    "            \n",
    "            # Write \n",
    "            fw.write(word + \" \" + tag + \" \" + \"O - O\" + \"\\n\")\n",
    "            \n",
    "        # Close sentence\n",
    "        fw.write(\"\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open corpus\n",
    "with io.open(_PATH_CORPORA + \"corpora/UNIFESP.txt\", 'r', encoding='utf8') as f:\n",
    "    \n",
    "    # Get the text\n",
    "    text = f.read()\n",
    "    \n",
    "    # Define replace lists\n",
    "    # More on https://www.infoescola.com/portugues/pronomes/ and https://www.infoescola.com/portugues/adverbios/\n",
    "    PRNtoDT = [\"esta\", \"este\", \"estas\", \"estes\", \"isto\", \"isso\", \"aquilo\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"sua\", \"seu\", \"suas\", \"seus\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"demais\", \"os demais\", \"as demais\", \"todo\", \"todos\", \"qual\",\"alguma\",\"algum\",\"algumas\",\"alguns\",\"outro\",\"outra\",\"outros\",\"outras\",\"mesmo\",\"mesma\",\"mesmos\",\"mesmas\",\"neste\",\"nesta\",\"nestes\",\"nestas\",\"tanto\",\"cada\", \"quanto\", \"quantos\", \"quanta\", \"quantas\"]\n",
    "    PRNtoPRP = [\"eu\", \"tu\", \"ele\", \"ela\", \"nós\", \"vós\", \"eles\", \"elas\", \"me\", \"mim\", \"comigo\", \"te\", \"ti\", \"contigo\", \"se\", \"si\", \"consigo\", \"o\", \"a\", \"lhe\", \"nos\", \"conosco\", \"vos\", \"convosco\", \"os\", \"as\", \"lhes\", \"lo\", \"la\", \"los\", \"las\", \"mim\"]\n",
    "    PRNtoPRPS = [\"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\",\"teus\", \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"seu\", \"sua\", \"seus\", \"suas\"]\n",
    "    ###PRNtoSPEC = [\"que\", \"quem\", \"nada\", \"cada um\", \"as quais\", \"os quais\", \"a qual\", \"o qual\", \"onde\", \"todo o mundo\"]\n",
    "    \n",
    "    #Iterate through sentences\n",
    "    for s in text.split(\"\\n\"):\n",
    "        \n",
    "        fw2.write(\"\\n\")\n",
    "        \n",
    "        #Iterate through tokens\n",
    "        for t in s.split(\" \"):\n",
    "            \n",
    "            item = t.split(\"_\")\n",
    "             \n",
    "            wordNorm = item[0]#normalizar acentos e case\n",
    "            \n",
    "            for i in wordNorm:\n",
    "                accented_word = wordNorm\n",
    "                # accented_word is of type 'unicode'\n",
    "            \n",
    "                unaccented_word = unidecode.unidecode(accented_word)\n",
    "                # unaccented_word contains 'Malaga'and is of type 'str'\n",
    "                \n",
    "            for i in unaccented_word:\n",
    "                word2 = unaccented_word.lower()\n",
    "            \n",
    "            tag2 = item[1]\n",
    "               \n",
    "            dictTags2[tag2] = dictTags2.get(tag2, 0) + 1\n",
    "\n",
    "            # Any DET Inflection -> DET\n",
    "            # Any PROP Inflection -> PROP\n",
    "            # Any ADJ Inflection -> ADJ\n",
    "            \n",
    "            # PRP to IN (prepositions)\n",
    "            if tag2.upper() == \"PRP\":\n",
    "                tag2 = tag2.replace(\"PRP\", \"IN\")\n",
    "                dictIN2[word2] = dictIN2.get(word2, 0) + 1\n",
    "            \n",
    "            # N and its inflections to NN and NNS (singular nouns and plural nouns)\n",
    "            if tag2.startswith(\"N\"):\n",
    "                # NFS and NMS to NN (singular nouns)\n",
    "                tag2 = tag2.replace(\"NFS\", \"NN\")\n",
    "                tag2 = tag2.replace(\"NMS\", \"NN\")\n",
    "                if tag2.upper() == \"NN\":\n",
    "                    dictNN2[word2] = dictNN2.get(word2, 0) + 1\n",
    "                \n",
    "                # NMP and NFP to NNS (plural nouns)\n",
    "                tag2 = tag2.replace(\"NMP\", \"NN\")\n",
    "                tag2 = tag2.replace(\"NFP\", \"NN\")\n",
    "                if tag2.upper() == \"NN\":\n",
    "                    dictNN2[word2] = dictNN2.get(word2, 0) + 1\n",
    "                \n",
    "                # NM to NN (singular nouns)\n",
    "                tag2 = tag2.replace(\"NM\", \"NN\")\n",
    "                dictNN2[word2] = dictNN2.get(word2, 0) + 1\n",
    "            \n",
    "            # PROP to NNP (proper nouns)\n",
    "            if tag2.startswith(\"PROP\"):\n",
    "                tag2 = \"NNP\"\n",
    "                dictNNP2[word2] = dictNNP2.get(word2, 0) + 1\n",
    "            \n",
    "            # generic rule for verbs\n",
    "            if tag2.startswith(\"V\"):\n",
    "            \n",
    "                # VINF to VB (verbs in base form)\n",
    "                if tag2.upper() == \"VINF\":\n",
    "                    tag2 = tag2.replace(\"VINF\", \"VB\")\n",
    "                    dictVB2[word2] = dictVB2.get(word2, 0) + 1\n",
    "                \n",
    "                # VFIN to VBP (non-third person verbs, singular present)         ### Rever regra\n",
    "                elif tag2.upper() == \"VFIN\":\n",
    "                    tag2 = tag2.replace(\"VFIN\", \"VB\")\n",
    "                    dictVB2[word2] = dictVB2.get(word2, 0) + 1\n",
    "                \n",
    "                elif tag2.upper() == \"VGER\":\n",
    "                    tag2 = tag2.replace(\"VGER\", \"VB\")\n",
    "                    dictVB2[word2] = dictVB2.get(word2, 0) + 1\n",
    "                \n",
    "                # VPCP and its inflections to VNB (past participle verb)  \n",
    "                elif tag2.startswith(\"VPCP\"):\n",
    "                    tag2 = tag2.replace(\"VPCPMS\", \"VB\")\n",
    "                    tag2 = tag2.replace(\"VPCPFS\", \"VB\")\n",
    "                    tag2 = tag2.replace(\"VPCPMP\", \"VB\")\n",
    "                    tag2 = tag2.replace(\"VPCPFP\", \"VB\")\n",
    "                    dictVB2[word2] = dictVB2.get(word2, 0) + 1\n",
    "                \n",
    "                # Rule for those others verb forms who nobody understards\n",
    "                else:\n",
    "                    tag2 = \"VB\"\n",
    "                    dictVB2[word2] = dictVB2.get(word2, 0) + 1\n",
    "            \n",
    "            # SPEC to DT (determiners)\n",
    "            if tag.startswith(\"SPEC\"):\n",
    "                tag = \"DT\"\n",
    "                dictDT2[word] = dictDT2.get(word, 0) + 1\n",
    "            \n",
    "            # DET and its inflections to DT (determiners)\n",
    "            if tag2.startswith(\"DET\"):\n",
    "                tag2 = \"DT\"\n",
    "                dictDT2[word2] = dictDT2.get(word2, 0) + 1\n",
    "            \n",
    "            # PERS to PRP (personal pronouns)\n",
    "            if tag2.startswith(\"PERS\"):\n",
    "                tag2 = \"PRP\"\n",
    "                dictPRP2[word2] = dictPRP2.get(word2, 0) + 1\n",
    "            \n",
    "            # ADJ to JJ (adjetives)\n",
    "            if tag2.startswith(\"ADJ\"):\n",
    "                tag2 = \"JJ\"\n",
    "                dictJJ2[word2] = dictJJ2.get(word2, 0) + 1\n",
    "            \n",
    "            # NUM and its inflections to CD (cardinal numbers)\n",
    "            if tag2.startswith(\"NUM\"):\n",
    "                tag2 = \"CD\"\n",
    "                dictCD2[word2] = dictCD2.get(word2, 0) + 1\n",
    "            \n",
    "            # ADV to RB (adverbs)\n",
    "            if tag2.startswith(\"ADV\"):\n",
    "                tag2 = \"RB\"\n",
    "                dictRB2[word2] = dictRB2.get(word2, 0) + 1\n",
    "            \n",
    "            # KC to CC or IN (coordinating or subordinating conjunctions)\n",
    "            if tag2.upper() == \"KC\":\n",
    "                if word2.lower() == \"e\" or word2.lower() == \"ou\":  \n",
    "                    #e, ou (coordinating conjuctions)\n",
    "                    tag2 = \"CC\" \n",
    "                    dictCC2[word2] = dictCC2.get(word2, 0) + 1\n",
    "                else:\n",
    "                    # \"que\", \"se\", \"porque\", etc (subordinating conjuctions)\n",
    "                    tag2 = \"IN\"\n",
    "                    dictIN2[word2] = dictIN2.get(word2, 0) + 1\n",
    "            \n",
    "            # KS to IN (subordinating conjunctions)\n",
    "            if tag2.upper() == \"KS\":\n",
    "                tag2 = \"IN\"\n",
    "                dictIN2[word2] = dictIN2.get(word2, 0) + 1\n",
    "            \n",
    "            # Other corrections - Common errors\n",
    "            # If the word SUS is labelled as an interjection\n",
    "            if word2.lower() == \"sus\" and tag2.upper() == \"IN\":\n",
    "                word2 = \"SUS\"\n",
    "                tag2 = \"NNP\"\n",
    "                dictNNP2[word2] = dictNNP2.get(word2, 0) + 1\n",
    "            \n",
    "            #Rule for 'finanças', taggeada errado provavelmente\n",
    "            if tag2.upper() == \"<NFP\":\n",
    "                tag2 = tag2.replace(\"<NFP\", \"NN\")\n",
    "                dictNN2[word2] = dictNN2.get(word2, 0) + 1\n",
    "            \n",
    "            #\"SEM\" is tagged as hyphen-separated and it's not. Switch to preposition\n",
    "            if word2.lower() == \"sem\" and tag2.upper() == \"EC\":\n",
    "                tag2 = tag2.replace(\"EC\", \"IN\")\n",
    "                dictIN2[word2] = dictIN2.get(word2, 0) + 1\n",
    "            \n",
    "            #\"PRÉ\" is tagged as hyphen-separated and it's not in the text. Switch to noun\n",
    "            if word2.lower() == \"pré\" and tag2.upper() == \"EC\":\n",
    "                tag2 = tag2.replace(\"EC\", \"NN\")\n",
    "                dictNN2[word2] = dictNN2.get(word2, 0) + 1\n",
    "            \n",
    "            #\"MICRO\" is tagged as hyphen-separated and it's not. Switch to noun\n",
    "            if word2.lower() == \"micro\" and tag2.upper() == \"EC\":\n",
    "                tag2 = tag2.replace(\"EC\", \"NN\")\n",
    "                dictNN2[word2] = dictNN2.get(word2, 0) + 1\n",
    "            \n",
    "            \n",
    "            ### Review word \"Espontânea\" - line 2972 - UNIFESP, with two tags for being spread out ###\n",
    "            ### Review words of type \"de=acordo\" tagged with \"PP\" ###\n",
    "            \n",
    "            \n",
    "            #TODO: If you find any other common error - put the correction here\n",
    "            \n",
    "            \n",
    "            #Dict for analysis of tags post normalization\n",
    "            dictTagsPostNormalization2[tag2] = dictTagsPostNormalization2.get(tag2, 0) + 1\n",
    "            \n",
    "            # Write \n",
    "            fw2.write(word2 + \" \" + tag2 + \" \" + \"O - O\" + \"\\n\")\n",
    "            \n",
    "        # Close sentence\n",
    "        fw2.write(\"\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictTags.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictTags2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of tags inside the corpus\n",
    "numberoftags = []\n",
    "for key, value in sorted(dictTagsPostNormalization.items(), key=lambda x:-x[1]):\n",
    "    numberoftags.append(value)\n",
    "    \n",
    "totalnumber = sum(numberoftags)\n",
    "print(totalnumber)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following cells show every word and its count in the corpus for each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictTagsPostNormalization.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictTagsPostNormalization2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVB.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVB2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVBP.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVBP2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVBG.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVBG2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVBN.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictVBN2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNN.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNN2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNNS.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNNS2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNNP.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictNNP2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictCD.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictCD2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPRP.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictPRP2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictJJ.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictJJ2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictDT.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictDT2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictIN.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictIN2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictCC.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictCC2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictRB.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sorted(dictRB2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
