{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Tue Dec 11 16:05:23 2018\\n\\n@author: Lucas Oliveira\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Lucas Ferro Antunes de Oliveira\n",
    "\"\"\"\n",
    "\n",
    "'''\n",
    "# This script transform the MACMORPHO corpus tagset to Penn Treebank tagset (with no INFLECTION tags)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unidecode in d:\\lucas\\programas\\anaconda\\envs\\flair\\lib\\site-packages (1.0.23)\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import collections\n",
    "import unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PATH_CORPORA = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionaries to count words and tags in the corpus\n",
    "\n",
    "dictTags = {}\n",
    "dictTags2 = {}\n",
    "dictTagsPostNormalization = {}\n",
    "dictTagsPostNormalization2 = {}\n",
    "\n",
    "dictPRN = {}\n",
    "dictART= {}\n",
    "dictN = {}\n",
    "dictPREP = {}\n",
    "dictADV = {}\n",
    "dictNUM = {}\n",
    "dictADJ = {}\n",
    "dictIN = {}\n",
    "dictNPROP = {}\n",
    "dictPCP = {}\n",
    "dictV = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More dictionaries\n",
    "\n",
    "dictPRN2 = {}\n",
    "dictART2= {}\n",
    "dictN2 = {}\n",
    "dictPREP2 = {}\n",
    "dictADV2 = {}\n",
    "dictNUM2 = {}\n",
    "dictADJ2 = {}\n",
    "dictIN2 = {}\n",
    "dictNPROP2 = {}\n",
    "dictPCP2 = {}\n",
    "dictV2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus file with the adapted tagset\n",
    "fw = io.open(_PATH_CORPORA + \"MACMORPHO-tagset-adapted-penntreebank-update.txt\",'w',encoding='utf8')\n",
    "fw.write(\"-DOCSTART- -X- -X- O\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new corpus file with the adapted normalized tagset\n",
    "fw2 = io.open(_PATH_CORPORA + \"MACMORPHO-tagset-adapted-penntreebank-no-accents.txt\",'w',encoding='utf8')\n",
    "fw2.write(\"-DOCSTART- -X- -X- O\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open corpus\n",
    "with io.open(_PATH_CORPORA + \"corpora\\Macmorpho/macmorpho.txt\",'r',encoding='utf8') as f:\n",
    "    \n",
    "    # Get the text\n",
    "    text = f.read()\n",
    "    \n",
    "    # Define replace lists\n",
    "    # More on https://www.infoescola.com/portugues/pronomes/ and https://www.infoescola.com/portugues/adverbios/\n",
    "    PRNtoDT = [\"esta\", \"este\", \"estas\", \"estes\", \"isto\", \"isso\", \"aquilo\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"sua\", \"seu\", \"suas\", \"seus\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"demais\", \"os demais\", \"as demais\", \"todo\", \"todos\", \"qual\",\"alguma\",\"algum\",\"algumas\",\"alguns\",\"outro\",\"outra\",\"outros\",\"outras\",\"mesmo\",\"mesma\",\"mesmos\",\"mesmas\",\"neste\",\"nesta\",\"nestes\",\"nestas\",\"tanto\",\"cada\", \"quanto\", \"quantos\", \"quanta\", \"quantas\"]\n",
    "    PRNtoPRP = [\"eu\", \"tu\", \"ele\", \"ela\", \"nós\", \"vós\", \"eles\", \"elas\", \"me\", \"mim\", \"comigo\", \"te\", \"ti\", \"contigo\", \"se\", \"si\", \"consigo\", \"o\", \"a\", \"lhe\", \"nos\", \"conosco\", \"vos\", \"convosco\", \"os\", \"as\", \"lhes\", \"lo\", \"la\", \"los\", \"las\", \"mim\"]\n",
    "    PRNtoPRPS = [\"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\",\"teus\", \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"seu\", \"sua\", \"seus\", \"suas\"]\n",
    "    \n",
    "    #Define contractions list for expansion purposes\n",
    "    # https://pt.wiktionary.org/wiki/Ap%C3%AAndice:Combina%C3%A7%C3%B5es_e_contra%C3%A7%C3%B5es_do_portugu%C3%AAs\n",
    "    contractionDict = {\n",
    "        \"à\": \"a_IN a_DT \",\n",
    "        \"às\": \"a_IN as_DT \",  \n",
    "        \"ao\": \"a_IN o_DT \",\n",
    "        \"aos\": \"a_IN os_DT \",\n",
    "        \"do\": \"de_IN o_DT \",\n",
    "        \"da\": \"de_IN a_DT \",\n",
    "        \"dos\": \"de_IN os_DT \",\n",
    "        \"das\": \"de_IN as_DT \",\n",
    "        \"no\": \"em_IN o_DT \",\n",
    "        \"na\": \"em_IN a_DT \",\n",
    "        \"nos\": \"em_IN os_DT \",\n",
    "        \"nas\": \"em_IN as_DT \",\n",
    "        \"pro\": \"para_IN o_DT \",\n",
    "        \"pra\": \"para_IN a_DT \",\n",
    "        \"pros\": \"para_IN os_DT \",\n",
    "        \"pras\": \"para_IN as_DT \",\n",
    "        \"pelo\": \"per_IN o_DT \",\n",
    "        \"pela\": \"per_IN a_DT \",\n",
    "        \"pelos\": \"per_IN os_DT \",\n",
    "        \"pelas\": \"per_IN as_DT \",\n",
    "        \"cum\": \"com_IN um_DT \",\n",
    "        \"dum\": \"de_IN um_DT \",\n",
    "        \"duns\": \"de_IN uns_DT \",\n",
    "        \"duma\": \"de_IN uma_DT \",\n",
    "        \"dumas\": \"de_IN umas_DT \",\n",
    "        \"num\": \"em_IN um_DT \",\n",
    "        \"nuns\": \"em_IN uns_DT \",\n",
    "        \"numa\": \"em_IN uma_DT \",\n",
    "        \"numas\": \"em_IN umas_DT \",\n",
    "        \"prum\": \"para_IN um_DT \",\n",
    "        \"pruns\": \"para_IN uns_DT \",\n",
    "        \"pruma\": \"para_IN uma_DT \",\n",
    "        \"prumas\": \"para_IN umas_DT \",\n",
    "        \"comigo\": \"com_IN mim_PRP \",\n",
    "        \"contigo\": \"com_IN ti_PRP \",\n",
    "        \"consigo\": \"com_IN si_PRP \",\n",
    "        \"conosco\": \"com_IN nós_PRP \",\n",
    "        \"convosco\": \"com_IN vós_PRP \",\n",
    "        \"d'ele\": \"de_IN ele_PRP \",\n",
    "        \"dele\": \"de_IN ele_PRP \",\n",
    "        \"dela\": \"de_IN ela_PRP \",\n",
    "        \"deles\": \"de_IN eles_PRP \",\n",
    "        \"delas\": \"de_IN elas_PRP \",\n",
    "        \"nele\": \"de_IN ele_PRP \",\n",
    "        \"nela\": \"de_IN ela_PRP \",\n",
    "        \"neles\": \"de_IN eles_PRP \",\n",
    "        \"nelas\": \"de_IN elas_PRP \",\n",
    "        \"àquele\": \"a_IN aquele_DT \",\n",
    "        \"àquela\": \"a_IN aquela_DT \",\n",
    "        \"àqueles\": \"a_IN aqueles_DT \",\n",
    "        \"àquelas\": \"a_IN aquelas_DT \",\n",
    "        \"àquilo\": \"a_IN aquilo_DT \",\n",
    "        \"deste\": \"de_IN este_DT \",\n",
    "        \"desta\": \"de_IN esta_DT \",\n",
    "        \"destes\": \"de_IN estes_DT \",\n",
    "        \"destas\": \"de_IN estas_DT \",\n",
    "        \"disto\": \"de_IN isto_DT \",\n",
    "        \"desse\": \"de_IN esse_DT \",\n",
    "        \"dessa\": \"de_IN essa_DT \",\n",
    "        \"desses\": \"de_IN esses_DT \",\n",
    "        \"dessas\": \"de_IN essas_DT \",\n",
    "        \"disso\": \"de_IN isso_DT \",\n",
    "        \"daquele\": \"de_IN aquele_DT \",\n",
    "        \"daquela\": \"de_IN aquela_DT \",\n",
    "        \"daqueles\": \"de_IN aqueles_DT \",\n",
    "        \"daquelas\": \"de_IN aquelas_DT \",\n",
    "        \"daquilo\": \"de_IN aquilo_DT \",\n",
    "        \"neste\": \"em_IN este_DT \",\n",
    "        \"nesta\": \"em_IN esta_DT \",\n",
    "        \"nestes\": \"em_IN estes_DT \",\n",
    "        \"nestas\": \"em_IN estas_DT \",\n",
    "        \"nisto\": \"em_IN isto_DT \",\n",
    "        \"nesse\": \"em_IN esse_DT \",\n",
    "        \"nessa\": \"em_IN essa_DT \",\n",
    "        \"nesses\": \"em_IN esses_DT \",\n",
    "        \"nessas\": \"em_IN essas_DT \",\n",
    "        \"nisso\": \"em_IN isso_DT \",\n",
    "        \"naquele\": \"em_IN aquele_DT \",\n",
    "        \"naquela\": \"em_IN aquela_DT \",\n",
    "        \"naqueles\": \"em_IN aqueles_DT \",\n",
    "        \"naquelas\": \"em_IN aquelas_DT \",\n",
    "        \"naquilo\": \"em_IN aquilo_DT \",\n",
    "        \"noutro\": \"em_IN outro_DT \",\n",
    "        \"noutros\": \"em_IN outros_DT \",\n",
    "        \"doutro\": \"de_IN outro_DT \",\n",
    "        \"doutra\": \"de_IN outra_DT \",\n",
    "        \"doutros\": \"de_IN outros_DT \",\n",
    "        \"doutras\": \"de_IN outras_DT \",\n",
    "        \"aonde\": \"a_IN onde_RB \",\n",
    "        \"daqui\": \"de_IN aqui_RB \",\n",
    "        \"daí\": \"de_IN aí_RB \",\n",
    "        \"dali\": \"de_IN ali_RB \",\n",
    "        \"daquém\": \"de_IN aquém_RB \",\n",
    "        \"dalém\": \"de_IN além_RB \",\n",
    "        \"donde\": \"de_IN onde_RB \",\n",
    "        \"pronde\": \"para_IN onde_RB \",\n",
    "        \"pelaí\": \"per_IN aí_RB \",\n",
    "        \"de\":\"de_DT \"#Error\n",
    "    }\n",
    "    \n",
    "    # Define PRO-KS transformations\n",
    "    PROKStoIN = [\"que\"]\n",
    "    PROKStoDT = [\"o\", \"a\", \"os\", \"as\", \"qual\", \"quais\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"quem\"]\n",
    "    \n",
    "    PROSUBtoDT = [\"a\",\"o\",\"as\",\"os\", \"um\", \"uma\", \"uns\", \"umas\", \"outro\", \"outros\",\"todos\",\"quem\", \"nada\",\"tudo\",\"isso\",\"ninguém\"]\n",
    "  \n",
    "    #Iterate through sentences\n",
    "    for s in text.split(\"\\n\"):\n",
    "        \n",
    "        #Iterate through tokens\n",
    "        fw.write(\"\\n\")\n",
    "        for t in s.split(\" \"):\n",
    "            \n",
    "            item = t.split(\"_\")\n",
    "             \n",
    "            word = item[0]\n",
    "             \n",
    "            tag = item[1]\n",
    "            \n",
    "            dictTags[tag] = dictTags.get(tag, 0) + 1\n",
    "            \n",
    "            # 1) PREP+ART, PREP+PROADJ, PREP+PROSUB, PREP+PROPESS, PREP+PRO-KS, PREP+ADV -> Expansion - This corpus doesn't have the expansion\n",
    "            if tag.startswith(\"PREP+\"):\n",
    "                 \n",
    "                #if is a contraction of 2 words -> expand\n",
    "                if word.lower() in contractionDict:\n",
    "                     \n",
    "                    # Write \n",
    "                    fw.write(contractionDict[word.lower()] + \"\\n\")\n",
    "                      \n",
    "                else:\n",
    "                    print(\"contraction not found: \" + word + \"_\" + tag + \" \")    \n",
    "                    # Write \n",
    "                    fw.write(word + \"_\" + tag + \" \")\n",
    "                     \n",
    "            else:\n",
    "            \n",
    "    \n",
    "                # REPLACE RULES\n",
    "                \n",
    "                # 1) N -> NN (noun, singular)\n",
    "                if len(tag) == 1 and tag == \"N\":\n",
    "                    if tag.upper() == \"N\":\n",
    "                        dictN[word] = dictN.get(word, 0) + 1    \n",
    "                        tag = tag.replace(\"N\", \"NN\")  #(Noun, Singular)\n",
    "            \n",
    "                # 2) PU -> Punctuation symbol\n",
    "                tag = tag.replace(\"PU\", word)\n",
    "                \n",
    "                # 3) NPROP -> NNP\n",
    "                tag = tag.replace(\"NPROP\", \"NNP\")\n",
    "                \n",
    "                # 4) PREP -> IN\n",
    "                tag = tag.replace(\"PREP\", \"IN\")\n",
    "                \n",
    "                # 5) ART -> DT\n",
    "                tag = tag.replace(\"ART\", \"DT\")\n",
    "                \n",
    "                # 6) PCP -> VB\n",
    "                tag = tag.replace(\"PCP\", \"VB\")\n",
    "                \n",
    "                #TODO: Review, maybe some words work as ADV or ADJ\n",
    "                # 7) PROADJ -> DT\n",
    "                tag = tag.replace(\"PROADJ\", \"DT\")\n",
    "               \n",
    "                # 8) PROPESS -> PRP\n",
    "                tag = tag.replace(\"PROPESS\", \"PRP\")\n",
    "                \n",
    "                # 9) PRO-KS -> IN/DT\n",
    "                if tag.upper() == \"PRO-KS\":\n",
    "               \n",
    "                    if word.lower() in PROKStoIN:  \n",
    "                        tag = \"IN\"\n",
    "                    else:\n",
    "                        if word.lower() in PROKStoDT:  \n",
    "                            tag = \"DT\"\n",
    "                        else:\n",
    "                            tag = \"DT\"\n",
    "                                 \n",
    "                # 10) ADJ -> JJ (adjectives)\n",
    "                if tag.upper() == \"ADJ\":\n",
    "                    dictADJ[word] = dictADJ.get(word, 0) + 1\n",
    "                    tag = tag.replace(\"ADJ\", \"JJ\")\n",
    "                \n",
    "                # 11) PROSUB -> DT\n",
    "                if tag.upper() == \"PROSUB\":\n",
    "               \n",
    "                    if word.lower() in PROSUBtoDT:  \n",
    "                        tag = \"DT\"\n",
    "                    else:\n",
    "                        tag = \"DT\"\n",
    "                 \n",
    "                # 12) V -> VB\n",
    "                if len(tag) == 1 and tag == \"V\":\n",
    "                    if tag.upper() == \"V\":\n",
    "                        dictV[word] = dictV.get(word, 0) + 1\n",
    "                        tag = tag.replace(\"V\", \"VB\") #Verbs on base form\n",
    "                \n",
    "                # 13) KC -> CC\n",
    "                if tag.upper() == \"KC\":\n",
    "                    tag = tag.replace(\"KC\", \"CC\")\n",
    "                    \n",
    "                # 15) KC -> CC\n",
    "                if tag.upper() == \"KS\":\n",
    "                    tag = tag.replace(\"KS\", \"IN\")\n",
    "                \n",
    "                # 16) ADV -> RB\n",
    "                if tag.upper() == \"ADV\":\n",
    "                    dictADV[word] = dictADV.get(word, 0) + 1\n",
    "                    tag = tag.replace(\"ADV\", \"RB\")\n",
    "                \n",
    "                # 17) NUM -> CD (cardinal numbers)\n",
    "                if tag.upper() == \"NUM\":\n",
    "                    dictNUM[word] = dictNUM.get(word, 0) + 1\n",
    "                    tag = tag.replace(\"NUM\", \"CD\")\n",
    "                \n",
    "                #TODO: Review, maybe some words work as other tags\n",
    "                # 18) PDEN -> RB\n",
    "                tag = tag.replace(\"PDEN\", \"RB\")  \n",
    "                \n",
    "                # 19) CUR -> NN\n",
    "                tag = tag.replace(\"CUR\", \"NN\")  \n",
    "                \n",
    "                #TODO: Review, maybe some words work as KS\n",
    "                # 20) PDEN -> RB\n",
    "                tag = tag.replace(\"ADV-KS\", \"RB\")  \n",
    "                \n",
    "                dictTagsPostNormalization[tag] = dictTagsPostNormalization.get(tag, 0) + 1\n",
    "                \n",
    "                # Write \n",
    "                fw.write(word + \" \" + tag + \" \" + \"O - O\" + \"\\n\")\n",
    "                \n",
    "                #TODO: normalize multiword expressions like UNIFESP corpus\n",
    "                \n",
    "        # Close sentence\n",
    "        fw.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open corpus\n",
    "with io.open(_PATH_CORPORA + \"corpora/Macmorpho/macmorpho.txt\",'r',encoding='utf8') as f:\n",
    "    \n",
    "    # Get the text\n",
    "    text = f.read()\n",
    "    \n",
    "    # Define replace lists\n",
    "    # More on https://www.infoescola.com/portugues/pronomes/ and https://www.infoescola.com/portugues/adverbios/\n",
    "    PRNtoDT = [\"esta\", \"este\", \"estas\", \"estes\", \"isto\", \"isso\", \"aquilo\", \"aquele\", \"aquela\", \"aqueles\", \"aquelas\", \"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\", \"teus\", \"tuas\", \"sua\", \"seu\", \"suas\", \"seus\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"demais\", \"os demais\", \"as demais\", \"todo\", \"todos\", \"qual\",\"alguma\",\"algum\",\"algumas\",\"alguns\",\"outro\",\"outra\",\"outros\",\"outras\",\"mesmo\",\"mesma\",\"mesmos\",\"mesmas\",\"neste\",\"nesta\",\"nestes\",\"nestas\",\"tanto\",\"cada\", \"quanto\", \"quantos\", \"quanta\", \"quantas\"]\n",
    "    PRNtoPRP = [\"eu\", \"tu\", \"ele\", \"ela\", \"nós\", \"vós\", \"eles\", \"elas\", \"me\", \"mim\", \"comigo\", \"te\", \"ti\", \"contigo\", \"se\", \"si\", \"consigo\", \"o\", \"a\", \"lhe\", \"nos\", \"conosco\", \"vos\", \"convosco\", \"os\", \"as\", \"lhes\", \"lo\", \"la\", \"los\", \"las\", \"mim\"]\n",
    "    PRNtoPRPS = [\"meu\", \"minha\", \"meus\", \"minhas\", \"teu\", \"tua\",\"teus\", \"tuas\", \"nosso\", \"nossa\", \"nossos\", \"nossas\", \"vosso\", \"vossa\", \"vossos\", \"vossas\", \"seu\", \"sua\", \"seus\", \"suas\"]\n",
    "    ###PRNtoSPEC = [\"que\", \"quem\", \"nada\", \"cada um\", \"as quais\", \"os quais\", \"a qual\", \"o qual\", \"onde\", \"todo o mundo\"]\n",
    "    \n",
    "    #Define contractions list for expansion purposes\n",
    "    # https://pt.wiktionary.org/wiki/Ap%C3%AAndice:Combina%C3%A7%C3%B5es_e_contra%C3%A7%C3%B5es_do_portugu%C3%AAs\n",
    "    contractionDict = {\n",
    "        \"à\": \"a_IN a_DT \",\n",
    "        \"às\": \"a_IN as_DT \",  \n",
    "        \"ao\": \"a_IN o_DT \",\n",
    "        \"aos\": \"a_IN os_DT \",\n",
    "        \"do\": \"de_IN o_DT \",\n",
    "        \"da\": \"de_IN a_DT \",\n",
    "        \"dos\": \"de_IN os_DT \",\n",
    "        \"das\": \"de_IN as_DT \",\n",
    "        \"no\": \"em_IN o_DT \",\n",
    "        \"na\": \"em_IN a_DT \",\n",
    "        \"nos\": \"em_IN os_DT \",\n",
    "        \"nas\": \"em_IN as_DT \",\n",
    "        \"pro\": \"para_IN o_DT \",\n",
    "        \"pra\": \"para_IN a_DT \",\n",
    "        \"pros\": \"para_IN os_DT \",\n",
    "        \"pras\": \"para_IN as_DT \",\n",
    "        \"pelo\": \"per_IN o_DT \",\n",
    "        \"pela\": \"per_IN a_DT \",\n",
    "        \"pelos\": \"per_IN os_DT \",\n",
    "        \"pelas\": \"per_IN as_DT \",\n",
    "        \"cum\": \"com_IN um_DT \",\n",
    "        \"dum\": \"de_IN um_DT \",\n",
    "        \"duns\": \"de_IN uns_DT \",\n",
    "        \"duma\": \"de_IN uma_DT \",\n",
    "        \"dumas\": \"de_IN umas_DT \",\n",
    "        \"num\": \"em_IN um_DT \",\n",
    "        \"nuns\": \"em_IN uns_DT \",\n",
    "        \"numa\": \"em_IN uma_DT \",\n",
    "        \"numas\": \"em_IN umas_DT \",\n",
    "        \"prum\": \"para_IN um_DT \",\n",
    "        \"pruns\": \"para_IN uns_DT \",\n",
    "        \"pruma\": \"para_IN uma_DT \",\n",
    "        \"prumas\": \"para_IN umas_DT \",\n",
    "        \"comigo\": \"com_IN mim_PRP \",\n",
    "        \"contigo\": \"com_IN ti_PRP \",\n",
    "        \"consigo\": \"com_IN si_PRP \",\n",
    "        \"conosco\": \"com_IN nós_PRP \",\n",
    "        \"convosco\": \"com_IN vós_PRP \",\n",
    "        \"d'ele\": \"de_IN ele_PRP \",\n",
    "        \"dele\": \"de_IN ele_PRP \",\n",
    "        \"dela\": \"de_IN ela_PRP \",\n",
    "        \"deles\": \"de_IN eles_PRP \",\n",
    "        \"delas\": \"de_IN elas_PRP \",\n",
    "        \"nele\": \"de_IN ele_PRP \",\n",
    "        \"nela\": \"de_IN ela_PRP \",\n",
    "        \"neles\": \"de_IN eles_PRP \",\n",
    "        \"nelas\": \"de_IN elas_PRP \",\n",
    "        \"àquele\": \"a_IN aquele_DT \",\n",
    "        \"àquela\": \"a_IN aquela_DT \",\n",
    "        \"àqueles\": \"a_IN aqueles_DT \",\n",
    "        \"àquelas\": \"a_IN aquelas_DT \",\n",
    "        \"àquilo\": \"a_IN aquilo_DT \",\n",
    "        \"deste\": \"de_IN este_DT \",\n",
    "        \"desta\": \"de_IN esta_DT \",\n",
    "        \"destes\": \"de_IN estes_DT \",\n",
    "        \"destas\": \"de_IN estas_DT \",\n",
    "        \"disto\": \"de_IN isto_DT \",\n",
    "        \"desse\": \"de_IN esse_DT \",\n",
    "        \"dessa\": \"de_IN essa_DT \",\n",
    "        \"desses\": \"de_IN esses_DT \",\n",
    "        \"dessas\": \"de_IN essas_DT \",\n",
    "        \"disso\": \"de_IN isso_DT \",\n",
    "        \"daquele\": \"de_IN aquele_DT \",\n",
    "        \"daquela\": \"de_IN aquela_DT \",\n",
    "        \"daqueles\": \"de_IN aqueles_DT \",\n",
    "        \"daquelas\": \"de_IN aquelas_DT \",\n",
    "        \"daquilo\": \"de_IN aquilo_DT \",\n",
    "        \"neste\": \"em_IN este_DT \",\n",
    "        \"nesta\": \"em_IN esta_DT \",\n",
    "        \"nestes\": \"em_IN estes_DT \",\n",
    "        \"nestas\": \"em_IN estas_DT \",\n",
    "        \"nisto\": \"em_IN isto_DT \",\n",
    "        \"nesse\": \"em_IN esse_DT \",\n",
    "        \"nessa\": \"em_IN essa_DT \",\n",
    "        \"nesses\": \"em_IN esses_DT \",\n",
    "        \"nessas\": \"em_IN essas_DT \",\n",
    "        \"nisso\": \"em_IN isso_DT \",\n",
    "        \"naquele\": \"em_IN aquele_DT \",\n",
    "        \"naquela\": \"em_IN aquela_DT \",\n",
    "        \"naqueles\": \"em_IN aqueles_DT \",\n",
    "        \"naquelas\": \"em_IN aquelas_DT \",\n",
    "        \"naquilo\": \"em_IN aquilo_DT \",\n",
    "        \"noutro\": \"em_IN outro_DT \",\n",
    "        \"noutros\": \"em_IN outros_DT \",\n",
    "        \"doutro\": \"de_IN outro_DT \",\n",
    "        \"doutra\": \"de_IN outra_DT \",\n",
    "        \"doutros\": \"de_IN outros_DT \",\n",
    "        \"doutras\": \"de_IN outras_DT \",\n",
    "        \"aonde\": \"a_IN onde_RB \",\n",
    "        \"daqui\": \"de_IN aqui_RB \",\n",
    "        \"daí\": \"de_IN aí_RB \",\n",
    "        \"dali\": \"de_IN ali_RB \",\n",
    "        \"daquém\": \"de_IN aquém_RB \",\n",
    "        \"dalém\": \"de_IN além_RB \",\n",
    "        \"donde\": \"de_IN onde_RB \",\n",
    "        \"pronde\": \"para_IN onde_RB \",\n",
    "        \"pelaí\": \"per_IN aí_RB \",\n",
    "        \"de\":\"de_DT \"#Error\n",
    "    }\n",
    "    \n",
    "    # Define PRO-KS transformations\n",
    "    PROKStoIN = [\"que\"]\n",
    "    PROKStoDT = [\"o\", \"a\", \"os\", \"as\", \"qual\", \"quais\", \"cujo\", \"cuja\", \"cujos\", \"cujas\", \"quem\"]\n",
    "    \n",
    "    PROSUBtoDT = [\"a\",\"o\",\"as\",\"os\", \"um\", \"uma\", \"uns\", \"umas\", \"outro\", \"outros\",\"todos\",\"quem\", \"nada\",\"tudo\",\"isso\",\"ninguém\"]\n",
    "  \n",
    "    #Iterate through sentences\n",
    "    for s in text.split(\"\\n\"):\n",
    "        \n",
    "        #Iterate through tokens\n",
    "        fw2.write(\"\\n\")\n",
    "        for t in s.split(\" \"):\n",
    "            \n",
    "            item2 = t.split(\"_\")\n",
    "             \n",
    "            wordNorm = item2[0]\n",
    "            \n",
    "            for i in wordNorm:\n",
    "                accented_word = wordNorm\n",
    "                # accented_word is of type 'unicode'\n",
    "            \n",
    "                unaccented_word = unidecode.unidecode(accented_word)\n",
    "                # unaccented_word contains 'Malaga'and is of type 'str'\n",
    "                \n",
    "            for i in unaccented_word:\n",
    "                lowerword = unaccented_word.lower()\n",
    "            \n",
    "            tag2 = item2[1]\n",
    "            \n",
    "            \n",
    "            dictTags2[tag2] = dictTags2.get(tag2, 0) + 1\n",
    "            \n",
    "            # 1) PREP+ART, PREP+PROADJ, PREP+PROSUB, PREP+PROPESS, PREP+PRO-KS, PREP+ADV -> Expansion - This corpus doesn't have the expansion\n",
    "            if tag2.startswith(\"PREP+\"):\n",
    "                 \n",
    "                #if is a contraction of 2 words -> expand\n",
    "                if lowerword.lower() in contractionDict:\n",
    "                     \n",
    "                    # Write \n",
    "                    fw2.write(contractionDict[lowerword.lower()] + \"\\n\")\n",
    "                      \n",
    "                else:        \n",
    "                    # Write \n",
    "                    fw2.write(word + \" \" + tag + \" \" + \"O - O\" + \"\\n\")\n",
    "                     \n",
    "            else:\n",
    "            \n",
    "    \n",
    "                # REPLACE RULES\n",
    "                \n",
    "                # 1) N -> NN (noun, singular)\n",
    "                if len(tag2) == 1 and tag2 == \"N\":\n",
    "                    if tag2.upper() == \"N\":\n",
    "                        dictN2[lowerword] = dictN2.get(lowerword, 0) + 1    \n",
    "                        tag2 = tag2.replace(\"N\", \"NN\")  #(Noun, Singular)     ###Ainda falta plural (NNS)\n",
    "            \n",
    "                # 2) PU -> Punctuation symbol\n",
    "                tag2 = tag2.replace(\"PU\", lowerword)\n",
    "                \n",
    "                # 3) NPROP -> NNP\n",
    "                tag2 = tag2.replace(\"NPROP\", \"NNP\")\n",
    "                \n",
    "                # 4) PREP -> IN\n",
    "                tag2 = tag2.replace(\"PREP\", \"IN\")\n",
    "                \n",
    "                # 5) ART -> DT\n",
    "                tag2 = tag2.replace(\"ART\", \"DT\")\n",
    "                \n",
    "                # 6) PCP -> VB\n",
    "                tag2 = tag2.replace(\"PCP\", \"VB\")\n",
    "                \n",
    "                #TODO: Review, maybe some words work as ADV or ADJ\n",
    "                # 7) PROADJ -> DT\n",
    "                tag2 = tag2.replace(\"PROADJ\", \"DT\")\n",
    "               \n",
    "                # 8) PROPESS -> PRP\n",
    "                tag2 = tag2.replace(\"PROPESS\", \"PRP\")\n",
    "                \n",
    "                # 9) PRO-KS -> IN/DT\n",
    "                if tag2.upper() == \"PRO-KS\":\n",
    "               \n",
    "                    if lowerword.lower() in PROKStoIN:  \n",
    "                        tag2 = \"IN\"\n",
    "                    else:\n",
    "                        if lowerword.lower() in PROKStoDT:  \n",
    "                            tag2 = \"DT\"\n",
    "                        else:\n",
    "                            tag2 = \"DT\"\n",
    "                                 \n",
    "                # 10) ADJ -> JJ (adjectives)\n",
    "                if tag2.upper() == \"ADJ\":\n",
    "                    dictADJ2[lowerword] = dictADJ2.get(lowerword, 0) + 1\n",
    "                    tag2 = tag2.replace(\"ADJ\", \"JJ\")\n",
    "                \n",
    "                # 11) PROSUB -> DT\n",
    "                if tag2.upper() == \"PROSUB\":\n",
    "               \n",
    "                    if lowerword.lower() in PROSUBtoDT:  \n",
    "                        tag2 = \"DT\"\n",
    "                    else:\n",
    "                        tag2 = \"DT\"\n",
    "                 \n",
    "                # 12) V -> VB\n",
    "                if len(tag2) == 1 and tag2 == \"V\":\n",
    "                    if tag2.upper() == \"V\":\n",
    "                        dictV2[lowerword] = dictV2.get(lowerword, 0) + 1\n",
    "                        tag2 = tag2.replace(\"V\", \"VB\") #Verbs on base form\n",
    "                \n",
    "                # 13) KC -> CC\n",
    "                if tag2.upper() == \"KC\":\n",
    "                    tag2 = tag2.replace(\"KC\", \"CC\")\n",
    "                    \n",
    "                # 15) KC -> CC\n",
    "                if tag2.upper() == \"KS\":\n",
    "                    tag2 = tag2.replace(\"KS\", \"IN\")\n",
    "                \n",
    "                # 16) ADV -> RB\n",
    "                if tag2.upper() == \"ADV\":\n",
    "                    dictADV2[lowerword] = dictADV2.get(lowerword, 0) + 1\n",
    "                    tag2 = tag2.replace(\"ADV\", \"RB\")\n",
    "                \n",
    "                # 17) NUM -> CD (cardinal numbers)\n",
    "                if tag2.upper() == \"NUM\":\n",
    "                    dictNUM2[lowerword] = dictNUM2.get(lowerword, 0) + 1\n",
    "                    tag2 = tag2.replace(\"NUM\", \"CD\")\n",
    "                \n",
    "                #TODO: Review, maybe some words work as other tags\n",
    "                # 18) PDEN -> RB\n",
    "                tag2 = tag2.replace(\"PDEN\", \"RB\")  \n",
    "                \n",
    "                # 19) CUR -> NN\n",
    "                tag2 = tag2.replace(\"CUR\", \"NN\")  \n",
    "                \n",
    "                #TODO: Review, maybe some words work as KS\n",
    "                # 20) PDEN -> RB\n",
    "                tag2 = tag2.replace(\"ADV-KS\", \"RB\")  \n",
    "                   \n",
    "                dictTagsPostNormalization2[tag2] = dictTagsPostNormalization2.get(tag2, 0) + 1\n",
    "                \n",
    "                # Write \n",
    "                fw2.write(lowerword + \" \" + tag2 + \" \" + \"O - O\" + \"\\n\")\n",
    "                \n",
    "                #TODO: normalize multiword expressions like UNIFESP corpus\n",
    "                \n",
    "        # Close sentence\n",
    "        fw2.write(\"\")\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 200977\n",
      "PU = 138865\n",
      "V = 99621\n",
      "NPROP = 91765\n",
      "PREP = 91314\n",
      "ART = 68618\n",
      "PREP+ART = 58335\n",
      "ADJ = 43269\n",
      "ADV = 24814\n",
      "KC = 23366\n",
      "PCP = 19548\n",
      "NUM = 16181\n",
      "PROADJ = 15415\n",
      "KS = 12099\n",
      "PROPESS = 11538\n",
      "PRO-KS = 10919\n",
      "PROSUB = 6381\n",
      "PDEN = 5666\n",
      "CUR = 2473\n",
      "PREP+PROADJ = 1715\n",
      "ADV-KS = 1041\n",
      "PREP+PROSUB = 710\n",
      "PREP+PROPESS = 533\n",
      "IN = 284\n",
      "PREP+PRO-KS = 219\n",
      "PREP+ADV = 85\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(dictTags.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN = 203450\n",
      "VB = 119169\n",
      "IN = 112908\n",
      "DT = 92122\n",
      "NNP = 91765\n",
      ", = 56700\n",
      ". = 43564\n",
      "JJ = 43269\n",
      "RB = 31521\n",
      "CC = 23366\n",
      "\" = 17201\n",
      "CD = 16181\n",
      "PRP = 11538\n",
      ") = 6539\n",
      "( = 6526\n",
      "- = 2544\n",
      ": = 2315\n",
      "? = 1204\n",
      "! = 715\n",
      "... = 518\n",
      "; = 509\n",
      "' = 403\n",
      "/ = 81\n",
      "[ = 21\n",
      "(( = 9\n",
      ")) = 9\n",
      "` = 3\n",
      "Br- = 1\n",
      "Joe = 1\n",
      "Capote = 1\n",
      "NNP, = 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(dictTagsPostNormalization.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 200977\n",
      "PU = 138865\n",
      "V = 99621\n",
      "NPROP = 91765\n",
      "PREP = 91314\n",
      "ART = 68618\n",
      "PREP+ART = 58335\n",
      "ADJ = 43269\n",
      "ADV = 24814\n",
      "KC = 23366\n",
      "PCP = 19548\n",
      "NUM = 16181\n",
      "PROADJ = 15415\n",
      "KS = 12099\n",
      "PROPESS = 11538\n",
      "PRO-KS = 10919\n",
      "PROSUB = 6381\n",
      "PDEN = 5666\n",
      "CUR = 2473\n",
      "PREP+PROADJ = 1715\n",
      "ADV-KS = 1041\n",
      "PREP+PROSUB = 710\n",
      "PREP+PROPESS = 533\n",
      "IN = 284\n",
      "PREP+PRO-KS = 219\n",
      "PREP+ADV = 85\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(dictTags2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884154\n"
     ]
    }
   ],
   "source": [
    "numberoftags = []\n",
    "for key, value in sorted(dictTagsPostNormalization.items(), key=lambda x:-x[1]):\n",
    "    numberoftags.append(value)\n",
    "    \n",
    "totalnumber = sum(numberoftags)\n",
    "print(totalnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN = 203450\n",
      "VB = 119169\n",
      "IN = 112911\n",
      "DT = 92119\n",
      "NNP = 91765\n",
      ", = 56700\n",
      ". = 43564\n",
      "JJ = 43269\n",
      "RB = 31521\n",
      "CC = 23366\n",
      "\" = 17201\n",
      "CD = 16181\n",
      "PRP = 11538\n",
      ") = 6539\n",
      "( = 6526\n",
      "- = 2544\n",
      ": = 2315\n",
      "? = 1204\n",
      "! = 715\n",
      "... = 518\n",
      "; = 509\n",
      "' = 403\n",
      "/ = 81\n",
      "[ = 21\n",
      "(( = 9\n",
      ")) = 9\n",
      "` = 3\n",
      "br- = 1\n",
      "joe = 1\n",
      "capote = 1\n",
      "nprop, = 1\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(dictTagsPostNormalization2.items(), key=lambda x:-x[1]):\n",
    "    print(key + \" = \" +  str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
